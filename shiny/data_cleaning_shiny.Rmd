---
title: "Data Cleaning"
output: github_document
always_allow_html: true
---

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(readxl)
```


```{r, message=FALSE, warning=FALSE}
SNAP = 
  read_csv(file = "../Datasets/ACS_SNAP_ENROLLMENT.csv")|>
  janitor::clean_names()|>
  select(
    geo_id:s2201_c01_001e,
    s2201_c02_002e,
    s2201_c02_009e,
    s2201_c02_015e,
    s2201_c02_021e:s2201_c02_028e,
    s2201_c02_032e,
    s2201_c02_036e:s2201_c02_038e,
    s2201_c04_001e)|>
  select(-ends_with("m"))|>
  slice(-1)|>
  mutate(geoid = str_remove(geo_id, ".*US"))|>
  rename(
     total_ct_households = s2201_c01_001e,
     ph_elderly = s2201_c02_002e,
     ph_with_children = s2201_c02_009e,
     ph_no_children = s2201_c02_015e,
     ph_below_poverty = s2201_c02_021e,
     ph_above_poverty = s2201_c02_022e,
     ph_disability = s2201_c02_023e,
     ph_no_disability = s2201_c02_024e,
     ph_white = s2201_c02_025e,
     ph_black = s2201_c02_026e,
     ph_asian = s2201_c02_028e,
     ph_hispanic = s2201_c02_032e,
     ph_no_work = s2201_c02_036e,
     ph_1_work = s2201_c02_037e,
     ph_2_work = s2201_c02_038e,
     ph_snap = s2201_c04_001e
  )|>
  mutate(across(total_ct_households:ph_snap, as.numeric),
         ph_other_race = 100-ph_white-ph_black-ph_asian,
         ph_non_hispanic = 100-ph_hispanic)|>
  select(geoid,name,ph_snap,everything())|>
  select(-geo_id)
```


## Historic Redlining Score Data


```{r}
redlining = 
  read_excel("../Datasets/Historic Redlining Score 2020B.xlsx")|>
  janitor::clean_names()|>
  select(-cbsa)|>
  mutate(fip = substr(geoid20, 1, 5),
         interval2020 = as.character(interval2020),
         red_grade = case_when(
           hrs2020 < 1.5 ~ "A",
           hrs2020 < 2.5 ~ "B",
           hrs2020 < 3.5 ~ "C",
           TRUE ~ "D"
         ))|>
  filter(fip %in% c("36005", "36047", "36061", "36081", "36085"))|>
  rename(geoid = geoid20)
```



```{r}
redlining_snap = 
  redlining|>
  left_join(SNAP, by = "geoid")|>
  filter(is.na(ph_snap)==FALSE)
```


## Recognized Healthy Store in NYC 


```{r, message=FALSE, warning=FALSE}
nyc_healthy_store = 
  read_csv("../Datasets/Recognized_Shop_Healthy_Stores.csv")|>
  janitor::clean_names()|>
  distinct(bin, .keep_all = TRUE)|>
  mutate(fipcode = case_when(
    borough == "Bronx" ~ "36005",
    borough == "Brooklyn" ~ "36047",
    borough == "New York" ~ "36061"
  ),
  ct_label = case_when(
    census_tract_2020 < 100 ~ paste0("00", census_tract_2020, "00"),
    census_tract_2020 < 1000 ~ paste0("0", census_tract_2020, "00"),
    census_tract_2020 < 1200 ~ paste0(census_tract_2020, "00"),
    census_tract_2020 < 10000 ~ paste0("00", census_tract_2020),
    census_tract_2020 < 100000 ~ paste0("0", census_tract_2020)
  ))|>
  select(store_name,borough,zip_code,latitude,longitude,fipcode, ct_label)|>
  filter(!is.na(ct_label))|>
  mutate(geoid = paste(fipcode, ct_label, sep = ""))|>
  select(-fipcode, -ct_label)

```


```{r, message=FALSE, warning=FALSE}
health_store_count = 
nyc_healthy_store|>
  group_by(geoid)|>
  summarise(count_healthy_stores=n())

#please note that healthy store count is only available in three boroughs so make sure you filter before the match
#example code for the match

redlining_snap|>
  filter(str_starts(geoid, "36005") | str_starts(geoid, "36047")| str_starts(geoid, "36061"))|>
  left_join(health_store_count,by="geoid")
```

## PLACE data 


```{r, message=FALSE, warning=FALSE}
place_crude =
  read_csv("../Datasets/PLACES.csv")|>
  janitor::clean_names()|>
  rename(geoid = location_id)|>
  select(geoid, measure:data_value, measure_id)


place_cleaned=
  place_crude|>
  filter(measure_id %in% c("DIABETES", "HIGHCHOL", "OBESITY"))|>
  pivot_wider(
    id_cols = geoid,
    names_from = measure_id,
    values_from = data_value
  )|>
  janitor::clean_names()|>
  mutate(geoid = as.character(geoid))
```
The description regarding the health indicators we have used for the analysis were indicated in the table below. 

